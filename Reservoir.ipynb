{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, mean_squared_error,\n",
    "    mean_absolute_error\n",
    ")\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import Ridge\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "os.makedirs(\"comparison_plots\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    \"\"\"\n",
    "    Loads, preprocesses, and transforms time series data for model training.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    - Loads and cleans the merged dataset from a CSV file.\n",
    "    - Converts categorical columns ('Axis' and 'Sober_classification') to numerical codes.\n",
    "    - Extracts temporal features from the timestamp (e.g., sine and cosine of time of day).\n",
    "    - Applies a centered rolling average to smooth the 'TAC_Reading' signal.\n",
    "    - Scales input features and target variable using MinMaxScaler.\n",
    "    - Generates windowed input-output sequences for time series modeling with a fixed delay.\n",
    "    - Converts the data into PyTorch tensors for training models like RNNs, LSTMs, or Echo State Networks.\n",
    "\n",
    "    Returns:\n",
    "        X_tensor (torch.Tensor): Input tensor of shape (num_samples, window_size, num_features),\n",
    "                                 containing sequential feature data.\n",
    "        y_tensor (torch.Tensor): Target tensor of shape (num_samples, 1),\n",
    "                                 containing delayed TAC readings.\n",
    "        scaler_y (MinMaxScaler): Scaler object used to normalize the target values,\n",
    "                                 useful for inverse transforming predictions later.\n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.read_csv(\"merged_data.csv\").dropna()\n",
    "    data['Axis'] = data['Axis'].astype('category').cat.codes\n",
    "    data['Sober_classification'] = data['Sober_classification'].astype('category').cat.codes\n",
    "\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.rename(columns={'pid': 'PID', 'Time': 'time'})\n",
    "    data['time_index'] = data.groupby('PID').cumcount()\n",
    "\n",
    "    data['minute_of_day'] = data['timestamp'].dt.hour * 60 + data['timestamp'].dt.minute\n",
    "    data['sin_time'] = np.sin(2 * np.pi * data['minute_of_day'] / 1440)\n",
    "    data['cos_time'] = np.cos(2 * np.pi * data['minute_of_day'] / 1440)\n",
    "\n",
    "    data['TAC_Reading'] = data['TAC_Reading'].rolling(window=3, center=True).mean()\n",
    "    data = data.dropna()\n",
    "\n",
    "    features = ['Pe_results', 'Comp_results', 'Axis', 'Sober_classification', 'sin_time', 'cos_time']\n",
    "    X = data[features].values.astype(np.float32)\n",
    "    y = data['TAC_Reading'].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "    def create_sequences(X, y, window_size=10, delay=5):\n",
    "        X_seq, y_seq = [], []\n",
    "        for i in range(len(X) - window_size - delay):\n",
    "            X_seq.append(X[i:i+window_size])\n",
    "            y_seq.append(y[i+window_size+delay])\n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "    X_seq, y_seq = create_sequences(X_scaled, y_scaled, window_size=10, delay=5)\n",
    "\n",
    "    X_tensor = torch.tensor(X_seq, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_seq, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X_tensor, y_tensor, scaler_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoStateModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Echo State Network (ESN) implementation for time series modeling.\n",
    "\n",
    "    This model uses a fixed randomly initialized reservoir with a sparse recurrent \n",
    "    weight matrix. The internal reservoir dynamics are governed by a spectral radius \n",
    "    and leaky rate. The output is a concatenation of summary statistics from the \n",
    "    reservoir states over the input sequence.\n",
    "\n",
    "    Attributes:\n",
    "        input_dim (int): Number of input features.\n",
    "        hidden_dim (int): Number of reservoir neurons.\n",
    "        output_dim (int): Number of output features (not used in current implementation).\n",
    "        leaky_rate (float): Leaky integration rate for the reservoir update.\n",
    "        W_in (nn.Parameter): Input-to-reservoir weight matrix.\n",
    "        W_res (nn.Parameter): Recurrent reservoir weight matrix (non-trainable).\n",
    "        bias (nn.Parameter): Bias term for reservoir update (non-trainable).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, spectral_radius=0.9, sparsity=0.05, leaky_rate=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the Echo State Network.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Dimensionality of the input data.\n",
    "            hidden_dim (int): Number of hidden reservoir units.\n",
    "            output_dim (int): Output dimension (can be used for downstream mapping).\n",
    "            spectral_radius (float): Desired spectral radius of the recurrent weight matrix.\n",
    "            sparsity (float): Fraction of non-zero connections in the recurrent weight matrix.\n",
    "            leaky_rate (float): Controls the speed of reservoir state updates.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.leaky_rate = leaky_rate\n",
    "        \n",
    "        self.W_in = nn.Parameter(torch.empty(hidden_dim, input_dim))\n",
    "        self.W_res = nn.Parameter(torch.empty(hidden_dim, hidden_dim), requires_grad=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_dim), requires_grad=False)\n",
    "        \n",
    "        self._initialize_weights(spectral_radius, sparsity)\n",
    "\n",
    "    def _initialize_weights(self, spectral_radius, sparsity):\n",
    "        \"\"\"\n",
    "        Initializes the input and recurrent reservoir weights.\n",
    "\n",
    "        The recurrent weight matrix is scaled to achieve the desired spectral radius,\n",
    "        and sparsity is applied to create a sparse reservoir.\n",
    "\n",
    "        Args:\n",
    "            spectral_radius (float): Desired spectral radius.\n",
    "            sparsity (float): Fraction of active connections in the recurrent matrix.\n",
    "        \"\"\"\n",
    "        torch.manual_seed(42)\n",
    "        nn.init.uniform_(self.W_in, -0.5, 0.5)\n",
    "        \n",
    "        mask = torch.rand(self.hidden_dim, self.hidden_dim) < sparsity\n",
    "        weights = torch.randn(self.hidden_dim, self.hidden_dim) * mask\n",
    "        \n",
    "        eigvals = torch.linalg.eigvals(weights).abs()\n",
    "        scale = spectral_radius / eigvals.max().real\n",
    "        self.W_res.data = weights * scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the Echo State Network.\n",
    "\n",
    "        For each timestep in the input sequence, updates the reservoir state using\n",
    "        leaky integration. Then, returns a summary vector formed by concatenating\n",
    "        the mean, standard deviation, and last state of the reservoir over the sequence.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, sequence_length, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Summary representation of shape (batch_size, hidden_dim * 3).\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        h = torch.zeros(batch_size, self.hidden_dim)\n",
    "        h_list = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            u = x[:, t, :]\n",
    "            h = (1 - self.leaky_rate) * h + self.leaky_rate * torch.tanh(\n",
    "                F.linear(u, self.W_in) + F.linear(h, self.W_res) + self.bias)\n",
    "            h_list.append(h.unsqueeze(1))\n",
    "        \n",
    "        h_stack = torch.cat(h_list, dim=1)\n",
    "        \n",
    "        h_summary = torch.cat([\n",
    "            h_stack.mean(dim=1),\n",
    "            h_stack.std(dim=1),\n",
    "            h_stack[:, -1, :]\n",
    "        ], dim=1)\n",
    "        \n",
    "        return h_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTILITY FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Root Mean Squared Error (RMSE) between true and predicted values.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground truth values.\n",
    "        y_pred (np.ndarray): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "        float: RMSE value.\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Mean Absolute Error (MAE) between true and predicted values.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground truth values.\n",
    "        y_pred (np.ndarray): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "        float: MAE value.\n",
    "    \"\"\"\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "\n",
    "def calculate_normalized_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Normalized Root Mean Squared Error (NRMSE).\n",
    "\n",
    "    Normalization is done using the range of true values.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground truth values.\n",
    "        y_pred (np.ndarray): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "        float: NRMSE value.\n",
    "    \"\"\"\n",
    "    rmse = calculate_rmse(y_true, y_pred)\n",
    "    return rmse / (np.max(y_true) - np.min(y_true))\n",
    "\n",
    "\n",
    "def plot_predictions_with_boundary(y_train, y_test, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Plots the true vs predicted TAC readings over the last 200 steps, with a sobriety boundary.\n",
    "\n",
    "    Args:\n",
    "        y_train (torch.Tensor): Training ground truth values.\n",
    "        y_test (torch.Tensor): Test ground truth values.\n",
    "        y_pred (torch.Tensor): Predicted values for the test set.\n",
    "        model_name (str): Name of the model for labeling and saving.\n",
    "    \"\"\"\n",
    "    y_train_cpu = y_train.detach().cpu().numpy().flatten()\n",
    "    y_test_cpu = y_test.detach().cpu().numpy().flatten()\n",
    "    y_pred_cpu = y_pred.detach().cpu().numpy().flatten()\n",
    "\n",
    "    full_true = np.concatenate([y_train_cpu, y_test_cpu])\n",
    "    full_pred = np.concatenate([y_train_cpu, y_pred_cpu])\n",
    "    true_zoomed = full_true[-200:]\n",
    "    pred_zoomed = full_pred[-200:]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(true_zoomed, label='True TAC', linewidth=2)\n",
    "    plt.plot(pred_zoomed, label='Predicted TAC', linewidth=2, linestyle='--')\n",
    "    plt.axhline(0.08, color='red', linestyle='--', label='Sober Boundary')\n",
    "    plt.title(f'{model_name} - Last 200 Steps Prediction')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('TAC Reading')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(\"comparison_plots\", exist_ok=True)\n",
    "    plt.savefig(f\"comparison_plots/{model_name}_predictions.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_model_metrics_bar(metrics_dict, model_name):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of different metrics for a single model.\n",
    "\n",
    "    Args:\n",
    "        metrics_dict (dict): Dictionary of metric names and their corresponding values.\n",
    "        model_name (str): Name of the model (used for title and saved filename).\n",
    "    \"\"\"\n",
    "    metric_names = list(metrics_dict.keys())\n",
    "    metric_values = [float(metrics_dict[m]) for m in metric_names]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(metric_names, metric_values, color='lightblue', edgecolor='black')\n",
    "    plt.title(f'{model_name} - Performance Metrics')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0, height * 1.01, f'{height:.4f}',\n",
    "                 ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"comparison_plots\", exist_ok=True)\n",
    "    plt.savefig(f'comparison_plots/{model_name}_metrics_bar.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_validation(model, X_train, y_train, X_test, y_test, model_name, epochs, lr=0.001):\n",
    "    \"\"\"\n",
    "    Trains an Echo State Network model using ridge regression and evaluates its performance.\n",
    "\n",
    "    This function simulates training across a given number of epochs by recalculating \n",
    "    states and fitting a new ridge regression model at each epoch. It logs training and \n",
    "    testing loss curves, saves model weights, and evaluates performance using various metrics.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Echo State Network model instance.\n",
    "        X_train (torch.Tensor): Training input sequences.\n",
    "        y_train (torch.Tensor): Training target values.\n",
    "        X_test (torch.Tensor): Test input sequences.\n",
    "        y_test (torch.Tensor): Test target values.\n",
    "        model_name (str): Name of the model for saving artifacts.\n",
    "        epochs (int): Number of training epochs.\n",
    "        lr (float, optional): Learning rate (not used since ridge regression is non-iterative). Default is 0.001.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            y_pred (torch.Tensor): Predicted values for the test set.\n",
    "            rmse (float): Root Mean Squared Error.\n",
    "            mae (float): Mean Absolute Error.\n",
    "            nrmse (float): Normalized RMSE.\n",
    "            sobriety_accuracy (float): Accuracy of predicting sobriety status (above/below 0.08 TAC).\n",
    "            pearson_corr (float): Pearson correlation coefficient between predicted and true TAC.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    model_folder = f'model_{model_name}_{epochs}_epochs'\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    total_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            train_states = model(X_train)\n",
    "            test_states = model(X_test)\n",
    "\n",
    "        ridge = Ridge(alpha=0.01)\n",
    "        ridge.fit(train_states.detach().numpy(), y_train.detach().numpy())\n",
    "\n",
    "        y_pred_train = ridge.predict(train_states.detach().numpy())\n",
    "        y_pred_test = ridge.predict(test_states.detach().numpy())\n",
    "\n",
    "        train_loss = mean_squared_error(y_train.detach().numpy(), y_pred_train)\n",
    "        test_loss = mean_squared_error(y_test.detach().numpy(), y_pred_test)\n",
    "        total_loss = train_loss + test_loss\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        total_losses.append(total_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}, Total Loss: {total_loss:.6f}\")\n",
    "\n",
    "    # Save loss curve CSV\n",
    "    loss_df = pd.DataFrame({\n",
    "        'epoch': list(range(epochs)),\n",
    "        'train_loss': train_losses,\n",
    "        'test_loss': test_losses,\n",
    "        'total_loss': total_losses\n",
    "    })\n",
    "    loss_csv_path = f\"{model_folder}/learning_curve.csv\"\n",
    "    loss_df.to_csv(loss_csv_path, index=False)\n",
    "    print(f\"Saved learning curve to: {loss_csv_path}\")\n",
    "\n",
    "    # Final model with all data\n",
    "    ridge = Ridge(alpha=0.01)\n",
    "    ridge.fit(train_states.detach().numpy(), y_train.detach().numpy())\n",
    "    y_pred = ridge.predict(test_states.detach().numpy())\n",
    "    y_pred = torch.tensor(y_pred, dtype=torch.float32)\n",
    "\n",
    "    torch.save(model.state_dict(), f'{model_folder}/{model_name}.pth')\n",
    "    np.save(f'{model_folder}/ridge_weights.npy', ridge.coef_)\n",
    "\n",
    "    y_test_np = y_test.detach().numpy().flatten()\n",
    "    y_pred_np = y_pred.detach().numpy().flatten()\n",
    "\n",
    "    rmse = calculate_rmse(y_test_np, y_pred_np)\n",
    "    mae = calculate_mae(y_test_np, y_pred_np)\n",
    "    nrmse = calculate_normalized_rmse(y_test_np, y_pred_np)\n",
    "    pearson_corr, _ = pearsonr(y_test_np, y_pred_np)\n",
    "\n",
    "    y_true_class = (y_test_np >= 0.08).astype(int)\n",
    "    y_pred_class = (y_pred_np >= 0.08).astype(int)\n",
    "    sobriety_accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        'True_TAC': y_test_np,\n",
    "        'Predicted_TAC': y_pred_np\n",
    "    }).to_csv(f\"{model_folder}/predictions_vs_actuals.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame([{\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'NRMSE': nrmse,\n",
    "        'Sobriety_Accuracy': sobriety_accuracy,\n",
    "        'Pearson_Correlation': pearson_corr\n",
    "    }]).to_csv(f\"{model_folder}/metrics.csv\", index=False)\n",
    "\n",
    "    print(f\"{model_name} Sobriety Accuracy: {sobriety_accuracy:.4f}\")\n",
    "\n",
    "    return y_pred, rmse, mae, nrmse, sobriety_accuracy, pearson_corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN EXECUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Reservoir with validation for 300 epochs...\n",
      "Epoch 1/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 10/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 20/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 30/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 40/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 50/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 60/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 70/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 80/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 90/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 100/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 110/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 120/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 130/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 140/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 150/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 160/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 170/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 180/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 190/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 200/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 210/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 220/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 230/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 240/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 250/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 260/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 270/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 280/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 290/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Epoch 300/300 - Train Loss: 0.004305, Test Loss: 0.014492, Total Loss: 0.018798\n",
      "Saved learning curve to: model_Reservoir_300_epochs/learning_curve.csv\n",
      "Reservoir Sobriety Accuracy: 0.8841\n",
      "\n",
      "--- Reservoir Metrics ---\n",
      "RMSE: 0.1204\n",
      "MAE: 0.0879\n",
      "NRMSE: 0.1261\n",
      "Pearson Correlation: 0.9061\n",
      "Sobriety Classification Accuracy: 0.8841\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main execution pipeline:\n",
    "    - Loads and preprocesses the time series data\n",
    "    - Splits data into training and testing sets\n",
    "    - Initializes and trains the Echo State Network model\n",
    "    - Evaluates the model and visualizes predictions and performance metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # Load and prepare the data\n",
    "    X_tensor, y_tensor, scaler_y = load_and_prepare_data()\n",
    "\n",
    "    # Split into train/test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tensor, y_tensor, test_size=0.2, random_state=seed\n",
    "    )\n",
    "\n",
    "    # Initialize the Echo State Network model\n",
    "    input_dim = X_train.shape[2]\n",
    "    model = EchoStateModel(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=1500,\n",
    "        output_dim=1,\n",
    "        spectral_radius=0.95,\n",
    "        sparsity=0.05,\n",
    "        leaky_rate=0.1\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining Reservoir with validation for 300 epochs...\")\n",
    "    y_pred, rmse, mae, nrmse, sobriety_acc, pearson_corr = train_model_with_validation(\n",
    "        model, X_train, y_train, X_test, y_test, model_name=\"Reservoir\", epochs=300\n",
    "    )\n",
    "\n",
    "    # Plot predictions against true values with boundary marker\n",
    "    plot_predictions_with_boundary(y_train, y_test, y_pred, \"Reservoir\")\n",
    "\n",
    "    # Metrics summary dictionary\n",
    "    metrics = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'NRMSE': nrmse,\n",
    "        'Sobriety Accuracy': sobriety_acc,\n",
    "        'Pearson Correlation': pearson_corr\n",
    "    }\n",
    "\n",
    "    # Plot performance metrics\n",
    "    plot_model_metrics_bar(metrics, model_name=\"Reservoir\")\n",
    "\n",
    "    # Print metrics to console\n",
    "    print(\"\\n--- Reservoir Metrics ---\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
